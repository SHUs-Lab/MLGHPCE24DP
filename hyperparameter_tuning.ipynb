{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 18:05:03.162280: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-15 18:05:03.200168: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-15 18:05:03.200192: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-15 18:05:03.201097: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-15 18:05:03.207084: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-15 18:05:04.037273: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/dp1200@unt.ad.unt.edu/.venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback\n",
      "  backends.update(_get_backends(\"networkx.backends\"))\n"
     ]
    }
   ],
   "source": [
    "import torch , numpy as np, torch_geometric, random, pickle\n",
    "from deephyper.problem import HpProblem\n",
    "import ray\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda._device_count_nvml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class AMDGCNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.gcn1 = torch_geometric.nn.GATConv(16, 32, edge_dim=2)\n",
    "        self.gcn2 = torch_geometric.nn.GATConv(32, 32, edge_dim=2)\n",
    "        self.gcn3 = torch_geometric.nn.GATConv(32, 32, edge_dim=2)\n",
    "        self.gcn4 = torch_geometric.nn.GATConv(32, 1, edge_dim=2)\n",
    "        self.global_pool = torch_geometric.nn.aggr.SortAggregation(k=30)\n",
    "        self.conv1 = torch.nn.Conv1d(1, 16, 97, 97)\n",
    "        self.conv2 = torch.nn.Conv1d(16, 32, 5, 1)\n",
    "        self.maxpool = torch.nn.MaxPool1d(2, 2)\n",
    "        self.linear1 = torch.nn.Linear(352, 128)\n",
    "        self.linear2 = torch.nn.Linear(128, 1)\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "    def forward(self, mat, edge_index):\n",
    "        h1 = self.gcn1(mat, edge_index).tanh()\n",
    "        h2 = self.gcn2(h1, edge_index).tanh()\n",
    "        h3 = self.gcn3(h2, edge_index).tanh()\n",
    "        h4 = self.gcn4(h3, edge_index).tanh()\n",
    "        h = torch.cat([h1, h2, h3, h4], dim=-1)\n",
    "        h = self.global_pool(h)\n",
    "        h = h.view(h.size(0), 1, h.size(-1))\n",
    "        h = self.conv1(h).relu()\n",
    "        h = self.maxpool(h)\n",
    "        h = self.conv2(h).relu()\n",
    "        h = h.view(h.size(0), -1)\n",
    "        h = self.linear1(h).relu()\n",
    "        h = self.dropout(h)\n",
    "        h = self.linear2(h).sigmoid()\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(k, model, optimizer, criterion, device):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    pos_batch_dat = np.load(f'pos_batch_{k}.npz', allow_pickle=True)\n",
    "    neg_batch_dat = np.load(f'neg_batch_{k}.npz', allow_pickle=True)\n",
    "    pos_edge_dat = np.load(f'pos_edge_attr_{k}.npz', allow_pickle=True)\n",
    "    neg_edge_dat = np.load(f'neg_edge_attr_{k}.npz', allow_pickle=True)\n",
    "    pos_table = pos_batch_dat.f.arr_0\n",
    "    neg_table = neg_batch_dat.f.arr_0\n",
    "    pos_edges = pos_edge_dat.f.arr_0\n",
    "    neg_edges = neg_edge_dat.f.arr_0\n",
    "    lab_t = [j for j in range(len(pos_table)+len(neg_table)-1)]\n",
    "    random.shuffle(lab_t)\n",
    "    print(f\"Batch {k} in progress\")\n",
    "    ind = 0\n",
    "    for i in lab_t:\n",
    "        label = None\n",
    "        g = None\n",
    "        x = None\n",
    "        e = None\n",
    "        if i < len(pos_table):\n",
    "            label = torch.tensor([1.], dtype=torch.float32).to(device)\n",
    "            g = pos_table[i][2]\n",
    "            x = pos_table[i][3]\n",
    "            e = pos_edges[i]\n",
    "        else:\n",
    "            label = torch.tensor([0.], dtype=torch.float32).to(device)\n",
    "            g = neg_table[i - len(pos_table)][2]\n",
    "            x = neg_table[i - len(pos_table)][3]\n",
    "            e = neg_edges[i - len(pos_table)]\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        inp = torch.sparse_coo_tensor(torch.tensor(g, dtype=torch.float32).to_sparse_coo().indices(), torch.tensor(e, dtype = torch.float32)).coalesce().to(device)\n",
    "        outputs = model( torch.tensor(x).to(torch.float32).to(device), inp)\n",
    "        # Compute the loss and its gradients\n",
    "        loss = criterion(outputs.view(1), label)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        ind +=1\n",
    "        running_loss += loss.item()\n",
    "        if ind == 197:\n",
    "            last_loss = running_loss # loss per batch\n",
    "            print(f'Output: {outputs}, label: {label}')\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            running_loss = 0.\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_acc(model, device):\n",
    "    #device = torch.device(\"cuda\")\n",
    "    torch.no_grad()\n",
    "    model.train(False)\n",
    "    actuals = []\n",
    "    expecteds = []\n",
    "    for k in range(31,40):\n",
    "        pos_batch_dat = np.load(f'pos_batch_{k}.npz', allow_pickle=True)\n",
    "        neg_batch_dat = np.load(f'neg_batch_{k}.npz', allow_pickle=True)\n",
    "        pos_edge_dat = np.load(f'pos_edge_attr_{k}.npz', allow_pickle=True)\n",
    "        neg_edge_dat = np.load(f'neg_edge_attr_{k}.npz', allow_pickle=True)\n",
    "        pos_table = pos_batch_dat.f.arr_0\n",
    "        neg_table = neg_batch_dat.f.arr_0\n",
    "        pos_edges = pos_edge_dat.f.arr_0\n",
    "        neg_edges = neg_edge_dat.f.arr_0\n",
    "        lab_t = [j for j in range(len(pos_table)+len(neg_table)-1)]\n",
    "        random.shuffle(lab_t)\n",
    "        print(f\"Batch {k} in progress\")\n",
    "        ind = 0\n",
    "        outs = []\n",
    "        temp_l = []\n",
    "        for i in lab_t:\n",
    "            label = None\n",
    "            g = None\n",
    "            x = None\n",
    "            e = None\n",
    "            if i < len(pos_table):\n",
    "                temp_l.append(1)\n",
    "                g = pos_table[i][2]\n",
    "                x = pos_table[i][3]\n",
    "                e = pos_edges[i]\n",
    "            else:\n",
    "                temp_l.append(0)\n",
    "                g = neg_table[i - len(pos_table)][2]\n",
    "                x = neg_table[i - len(pos_table)][3]\n",
    "                e = neg_edges[i - len(pos_table)]\n",
    "\n",
    "            # Make predictions for this batch\n",
    "            inp = torch.sparse_coo_tensor(torch.tensor(g, dtype=torch.float32).to_sparse_coo().indices(), torch.tensor(e, dtype = torch.float32)).coalesce().to(device)\n",
    "            outputs = model( torch.tensor(x).to(torch.float32).to(device), inp)\n",
    "            o = 0\n",
    "            if outputs.view(1)[0] > 0.5:\n",
    "                o = 1\n",
    "            outs.append(o)\n",
    "            torch.cuda.empty_cache()\n",
    "        expecteds.extend(temp_l)\n",
    "        actuals.extend(outs)\n",
    "        torch.cuda.empty_cache()\n",
    "    sum = 0.\n",
    "    for l in range(len(expecteds)):\n",
    "        if expecteds[l] == actuals[l]:\n",
    "            sum += 1\n",
    "    return sum/len(actuals)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run(job):\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = AMDGCNN()\n",
    "    model.train(True)\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr = job[\"learning_rate\"])\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    for epoch in range(job[\"num_epochs\"]):\n",
    "        for i in range(1, 31):\n",
    "            train_one_epoch(i, model, optimizer, criterion, device)\n",
    "    return get_acc(model, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "learning_rate, Type: UniformFloat, Range: [0.0001, 0.1], Default: 0.0005, on log-scale"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem = HpProblem()\n",
    "\n",
    "# Discrete hyperparameter (sampled with uniform prior)\n",
    "problem.add_hyperparameter((5, 20), \"num_epochs\", default_value=10)\n",
    "\n",
    "# Discrete and Real hyperparameters (sampled with log-uniform)\n",
    "problem.add_hyperparameter((0.0001, 0.1, \"log-uniform\"), \"learning_rate\", default_value=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 10:44:27,710\tINFO worker.py:1715 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    }
   ],
   "source": [
    "# We launch the Ray run-time and execute the `run` function\n",
    "# with the default configuration\n",
    "n_gpus = torch.cuda.device_count()\n",
    "is_gpu_available = torch.cuda.is_available()\n",
    "if is_gpu_available:\n",
    "    if not(ray.is_initialized()):\n",
    "        ray.init(num_cpus=n_gpus, num_gpus=n_gpus, log_to_driver=False)\n",
    "else:\n",
    "    if not(ray.is_initialized()):\n",
    "        ray.init(num_cpus=1, log_to_driver=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new evaluator with 2 workers and config: {'num_cpus': 2, 'num_cpus_per_task': 1, 'callbacks': [<deephyper.evaluator.callback.TqdmCallback object at 0x7f851c55d550>], 'num_gpus': 2, 'num_gpus_per_task': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dp1200@unt.ad.unt.edu/.venv/lib64/python3.9/site-packages/deephyper/evaluator/_evaluator.py:127: UserWarning: Applying nest-asyncio patch for IPython Shell!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from deephyper.evaluator import Evaluator\n",
    "from deephyper.evaluator.callback import TqdmCallback\n",
    "\n",
    "def get_evaluator(run_function):\n",
    "    # Default arguments for Ray: 1 worker and 1 worker per evaluation\n",
    "    method_kwargs = {\n",
    "        \"num_cpus\": 1,\n",
    "        \"num_cpus_per_task\": 1,\n",
    "        \"callbacks\": [TqdmCallback()]\n",
    "    }\n",
    "\n",
    "    # If GPU devices are detected then it will create 'n_gpus' workers\n",
    "    # and use 1 worker for each evaluation\n",
    "    if torch.cuda.is_available():\n",
    "        method_kwargs[\"num_cpus\"] = n_gpus\n",
    "        method_kwargs[\"num_gpus\"] = n_gpus\n",
    "        method_kwargs[\"num_cpus_per_task\"] = 1\n",
    "        method_kwargs[\"num_gpus_per_task\"] = 1\n",
    "\n",
    "    evaluator = Evaluator.create(\n",
    "        run_function,\n",
    "        method=\"ray\",\n",
    "        method_kwargs=method_kwargs\n",
    "    )\n",
    "    print(f\"Created new evaluator with {evaluator.num_workers} worker{'s' if evaluator.num_workers > 1 else ''} and config: {method_kwargs}\", )\n",
    "\n",
    "    return evaluator\n",
    "\n",
    "evaluator_1 = get_evaluator(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from deephyper.search.hps import CBO\n",
    "# Uncomment the following line to show the arguments of CBO.\n",
    "# CBO?\n",
    "# Instanciate the search with the problem and a specific evaluator\n",
    "search = CBO(problem, evaluator_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0766168d2cc4393a5343d970891a354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = search.search(max_evals=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresults\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "pickle.dump(results, 'results.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p:learning_rate</th>\n",
       "      <th>p:num_epochs</th>\n",
       "      <th>objective</th>\n",
       "      <th>job_id</th>\n",
       "      <th>m:timestamp_submit</th>\n",
       "      <th>m:timestamp_gather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000562</td>\n",
       "      <td>8</td>\n",
       "      <td>0.979131</td>\n",
       "      <td>0</td>\n",
       "      <td>1.465135</td>\n",
       "      <td>6849.214205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004340</td>\n",
       "      <td>15</td>\n",
       "      <td>0.497462</td>\n",
       "      <td>1</td>\n",
       "      <td>1.466548</td>\n",
       "      <td>12405.218339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.075996</td>\n",
       "      <td>14</td>\n",
       "      <td>0.502538</td>\n",
       "      <td>2</td>\n",
       "      <td>6849.245531</td>\n",
       "      <td>18422.994636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001667</td>\n",
       "      <td>14</td>\n",
       "      <td>0.502538</td>\n",
       "      <td>3</td>\n",
       "      <td>12405.243189</td>\n",
       "      <td>24205.495469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005337</td>\n",
       "      <td>9</td>\n",
       "      <td>0.502538</td>\n",
       "      <td>4</td>\n",
       "      <td>18423.019018</td>\n",
       "      <td>26079.387467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002732</td>\n",
       "      <td>6</td>\n",
       "      <td>0.502538</td>\n",
       "      <td>6</td>\n",
       "      <td>26079.413719</td>\n",
       "      <td>31268.952611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000497</td>\n",
       "      <td>6</td>\n",
       "      <td>0.521715</td>\n",
       "      <td>7</td>\n",
       "      <td>31268.976658</td>\n",
       "      <td>36478.823181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000229</td>\n",
       "      <td>17</td>\n",
       "      <td>0.561760</td>\n",
       "      <td>5</td>\n",
       "      <td>24205.525767</td>\n",
       "      <td>38487.672269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000569</td>\n",
       "      <td>12</td>\n",
       "      <td>0.959955</td>\n",
       "      <td>8</td>\n",
       "      <td>36478.849388</td>\n",
       "      <td>46586.471162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p:learning_rate  p:num_epochs  objective  job_id  m:timestamp_submit  \\\n",
       "0         0.000562             8   0.979131       0            1.465135   \n",
       "1         0.004340            15   0.497462       1            1.466548   \n",
       "2         0.075996            14   0.502538       2         6849.245531   \n",
       "3         0.001667            14   0.502538       3        12405.243189   \n",
       "4         0.005337             9   0.502538       4        18423.019018   \n",
       "5         0.002732             6   0.502538       6        26079.413719   \n",
       "6         0.000497             6   0.521715       7        31268.976658   \n",
       "7         0.000229            17   0.561760       5        24205.525767   \n",
       "8         0.000569            12   0.959955       8        36478.849388   \n",
       "\n",
       "   m:timestamp_gather  \n",
       "0         6849.214205  \n",
       "1        12405.218339  \n",
       "2        18422.994636  \n",
       "3        24205.495469  \n",
       "4        26079.387467  \n",
       "5        31268.952611  \n",
       "6        36478.823181  \n",
       "7        38487.672269  \n",
       "8        46586.471162  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('results.csv')\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dp1200@unt.ad.unt.edu/.venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback\n",
      "  backends.update(_get_backends(\"networkx.backends\"))\n"
     ]
    }
   ],
   "source": [
    "from ogb.linkproppred import PygLinkPropPredDataset\n",
    "\n",
    "dataset = PygLinkPropPredDataset(name = \"ogbl-biokg\") \n",
    "\n",
    "split_edge = dataset.get_edge_split()\n",
    "train_edge, valid_edge, test_edge = split_edge[\"train\"], split_edge[\"valid\"], split_edge[\"test\"]\n",
    "graph = dataset[0] # pyg graph object containing only training edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = graph.edge_index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'disease-protein': 0,\n",
       " 'drug-disease': 1,\n",
       " 'drug-drug_acquired_metabolic_disease': 2,\n",
       " 'drug-drug_bacterial_infectious_disease': 3,\n",
       " 'drug-drug_benign_neoplasm': 4,\n",
       " 'drug-drug_cancer': 5,\n",
       " 'drug-drug_cardiovascular_system_disease': 6,\n",
       " 'drug-drug_chromosomal_disease': 7,\n",
       " 'drug-drug_cognitive_disorder': 8,\n",
       " 'drug-drug_cryptorchidism': 9,\n",
       " 'drug-drug_developmental_disorder_of_mental_health': 10,\n",
       " 'drug-drug_endocrine_system_disease': 11,\n",
       " 'drug-drug_fungal_infectious_disease': 12,\n",
       " 'drug-drug_gastrointestinal_system_disease': 13,\n",
       " 'drug-drug_hematopoietic_system_disease': 14,\n",
       " 'drug-drug_hematopoietic_system_diseases': 15,\n",
       " 'drug-drug_hypospadias': 16,\n",
       " 'drug-drug_immune_system_disease': 17,\n",
       " 'drug-drug_inherited_metabolic_disorder': 18,\n",
       " 'drug-drug_integumentary_system_disease': 19,\n",
       " 'drug-drug_irritable_bowel_syndrome': 20,\n",
       " 'drug-drug_monogenic_disease': 21,\n",
       " 'drug-drug_musculoskeletal_system_disease': 22,\n",
       " 'drug-drug_nervous_system_disease': 23,\n",
       " 'drug-drug_orofacial_cleft': 24,\n",
       " 'drug-drug_parasitic_infectious_disease': 25,\n",
       " 'drug-drug_personality_disorder': 26,\n",
       " 'drug-drug_polycystic_ovary_syndrome': 27,\n",
       " 'drug-drug_pre-malignant_neoplasm': 28,\n",
       " 'drug-drug_psoriatic_arthritis': 29,\n",
       " 'drug-drug_reproductive_system_disease': 30,\n",
       " 'drug-drug_respiratory_system_disease': 31,\n",
       " 'drug-drug_sexual_disorder': 32,\n",
       " 'drug-drug_sleep_disorder': 33,\n",
       " 'drug-drug_somatoform_disorder': 34,\n",
       " 'drug-drug_struct_sim': 35,\n",
       " 'drug-drug_substance-related_disorder': 36,\n",
       " 'drug-drug_thoracic_disease': 37,\n",
       " 'drug-drug_urinary_system_disease': 38,\n",
       " 'drug-drug_viral_infectious_disease': 39,\n",
       " 'drug-protein': 40,\n",
       " 'drug-sideeffect': 41,\n",
       " 'function-function': 42,\n",
       " 'protein-function': 43,\n",
       " 'protein-protein_activation': 44,\n",
       " 'protein-protein_binding': 45,\n",
       " 'protein-protein_catalysis': 46,\n",
       " 'protein-protein_expression': 47,\n",
       " 'protein-protein_inhibition': 48,\n",
       " 'protein-protein_ptmod': 49,\n",
       " 'protein-protein_reaction': 50}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rels = {}\n",
    "for i in e.keys():\n",
    "    rels[i[1]] = len(rels)\n",
    "rels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_mat = np.zeros((10687+10533+45085+17499+9969, 5))\n",
    "node_dict = {'drug': 0, 'disease': 1, 'protein': 2, 'function': 3, 'sideeffect': 4}\n",
    "node_lab_adder = {'drug': 0, 'disease': 10533, 'protein': 10687+10533, 'function': 10687+17499+10533, 'sideeffect': 10687+17499+45085+10533}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in e:\n",
    "    edge_ind = e[i]\n",
    "    adder_1 = [node_lab_adder[i[0]]]*edge_ind.shape[1]\n",
    "    adder_2 = [node_lab_adder[i[2]]]*edge_ind.shape[1]\n",
    "    tens_add = torch.tensor([adder_1, adder_2])\n",
    "    edge_ind += tens_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in e:\n",
    "    edge_ind = e[i]\n",
    "    for f in edge_ind[0]:\n",
    "        node_mat[f][node_dict[i[0]]] = 1\n",
    "    for f in edge_ind[1]:\n",
    "        node_mat[f][node_dict[i[2]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_attr = torch.empty((0))\n",
    "edge_index = torch.tensor([[], []])\n",
    "attr_index = 0\n",
    "for i in e:\n",
    "    edge_index = torch.cat((edge_index, e[i]), 1)\n",
    "    attr_vec = np.zeros(51)\n",
    "    attr_vec[rels[i[1]]] = 1\n",
    "    a_m = torch.tile(torch.tensor(attr_vec), (e[i].shape[1], 1))\n",
    "    if edge_attr.shape == (0):\n",
    "        edge_attr = a_m\n",
    "    else:\n",
    "        edge_attr = torch.cat((edge_attr, a_m), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_graph = torch.sparse_coo_tensor(edge_index, edge_attr).coalesce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_table = set()\n",
    "table = []\n",
    "for i in e:\n",
    "    if rels[i[1]] < 44:\n",
    "        continue\n",
    "    batch = []\n",
    "    for j in range(e[i].shape[1]):\n",
    "        tup = (e[i][0][j], e[i][1][j])\n",
    "        tup_r = (e[i][1][j], e[i][0][j])\n",
    "        if tup in ind_table or tup_r in ind_table:\n",
    "            continue\n",
    "        ind_table.add(tup)\n",
    "        batch.append((e[i][0][j], e[i][1][j], rels[i[1]]))\n",
    "        if len(batch) >= 200:\n",
    "            break\n",
    "    table.extend(batch)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, random\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "from scipy.sparse.csgraph import shortest_path\n",
    "from torch_geometric.utils import to_scipy_sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_mat = torch.tensor(node_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SUBGRAPH EXTRACTION TESTING\n",
    "#Get Subgraph, DRNL\n",
    "\n",
    "def sg_gen(index):\n",
    "    n1 = table[index][0]\n",
    "    n2 = table[index][1]\n",
    "    subset, sg, new_targets, mask = k_hop_subgraph((n1, n2), 2, full_graph.indices(), relabel_nodes=True)\n",
    "    n_edge_atts = full_graph.values()[mask]\n",
    "    #Node attribute matrix gen\n",
    "    d_n1 = shortest_path(to_scipy_sparse_matrix(sg, num_nodes=len(subset)), directed=False, indices=new_targets[0])\n",
    "    d_n2 = shortest_path(to_scipy_sparse_matrix(sg, num_nodes=len(subset)), directed=False, indices=new_targets[1])\n",
    "    labels = torch.zeros(len(subset), dtype=torch.int64)\n",
    "    for i in range(len(subset)):\n",
    "        if d_n1[i] == 1 and d_n2[i] == 1:\n",
    "            labels[i] = 1\n",
    "        elif (d_n1[i] == 1 and d_n2[i] == 2) or (d_n1[i] == 2 and d_n2[i] == 1):\n",
    "            labels[i] = 2\n",
    "        elif d_n1[i] == 2 and d_n2[i] == 2:\n",
    "            labels[i] = 3\n",
    "        else:\n",
    "            labels[i] = 4\n",
    "    labels[new_targets[0]] = 0\n",
    "    labels[new_targets[1]] = 0\n",
    "    labels = torch.nn.functional.one_hot(labels, num_classes=5)\n",
    "    node_attr = torch.index_select(node_mat, 0, subset)\n",
    "    node_attr = torch.cat((node_attr, labels), 1)\n",
    "    sg = torch.sparse_coo_tensor(sg, n_edge_atts, size=(len(subset), len(subset), 51)).coalesce()\n",
    "\n",
    "    #sg = torch.sparse_coo_tensor(sg, torch.ones(len(sg[0])), size=(len(subset), len(subset))).coalesce()\n",
    "    #sg = sg.to_dense()\n",
    "    #sg[new_targets[0]][new_targets[1]] = 0\n",
    "    #sg[new_targets[1]][new_targets[0]] = 0\n",
    "    #sg = sg.to_sparse_coo()\n",
    "\n",
    "    inds = torch.tensor([[new_targets[0], new_targets[1]]]).transpose(1, 0)\n",
    "    del_tens = torch.sparse_coo_tensor(inds, torch.nn.functional.one_hot(torch.tensor([table[index][2]]), num_classes=51), size=sg.shape).float().coalesce()\n",
    "    sg -= del_tens\n",
    "    return sg, node_attr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 100 subgraphs\n",
      "Added 100 subgraphs\n",
      "Added 100 subgraphs\n",
      "Added 100 subgraphs\n",
      "Added 100 subgraphs\n",
      "Added 100 subgraphs\n",
      "Added 100 subgraphs\n",
      "Added 100 subgraphs\n",
      "Added 100 subgraphs\n",
      "Added 100 subgraphs\n",
      "Added 100 subgraphs\n",
      "Added 100 subgraphs\n",
      "Added 100 subgraphs\n"
     ]
    }
   ],
   "source": [
    "batch = []\n",
    "ind = 1\n",
    "inds = list(range(len(table)))\n",
    "random.shuffle(inds)\n",
    "for i in inds:\n",
    "    sg, x = sg_gen(i)\n",
    "    batch.append((table[i][2]-44, sg, x))\n",
    "    if len(batch)%100 == 0:\n",
    "        print(\"Added 100 subgraphs\")\n",
    "    if len(batch) == 1300:\n",
    "        break\n",
    "    '''if len(batch) >= 200:\n",
    "        pickle.dump(batch, open(f\"BioKG_Batch_{ind}.pickle\", 'wb'))\n",
    "        batch = []\n",
    "        ind += 1\n",
    "        print(f\"Added Batch {ind-1}\")\n",
    "if len(batch) > 0:\n",
    "    pickle.dump(batch, open(f\"BioKG_Batch_{ind}.pickle\", 'wb'))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv, aggr, GCNConv\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AMDGCNN(torch.nn.Module):\n",
    "    def __init__(self, dim_in):\n",
    "        super().__init__()\n",
    "        self.gcn1 = GATConv(dim_in, 32, edge_dim=51)\n",
    "        self.gcn2 = GATConv(32, 32, edge_dim=51)\n",
    "        self.gcn3 = GATConv(32, 32, edge_dim=51)\n",
    "        self.gcn4 = GATConv(32, 1, edge_dim=51)\n",
    "        self.global_pool = aggr.SortAggregation(k=30)\n",
    "        self.conv1 = torch.nn.Conv1d(1, 16, 97, 97)\n",
    "        self.conv2 = torch.nn.Conv1d(16, 32, 5, 1)\n",
    "        self.maxpool = torch.nn.MaxPool1d(2, 2)\n",
    "        self.linear1 = torch.nn.Linear(352, 128)\n",
    "        self.linear2 = torch.nn.Linear(128, 7)\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "    def forward(self, mat, edge_index):\n",
    "        h1 = self.gcn1(mat, edge_index).tanh()\n",
    "        h2 = self.gcn2(h1, edge_index).tanh()\n",
    "        h3 = self.gcn3(h2, edge_index).tanh()\n",
    "        h4 = self.gcn4(h3, edge_index).tanh()\n",
    "        h = torch.cat([h1, h2, h3, h4], dim=-1)\n",
    "        h = self.global_pool(h)\n",
    "        h = h.view(h.size(0), 1, h.size(-1))\n",
    "        h = self.conv1(h).relu()\n",
    "        h = self.maxpool(h)\n",
    "        h = self.conv2(h).relu()\n",
    "        h = h.view(h.size(0), -1)\n",
    "        h = self.linear1(h).relu()\n",
    "        h = self.dropout(h)\n",
    "        h = self.linear2(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No CUDA GPUs are available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 833\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1158\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/torch/cuda/__init__.py:298\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    297\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 298\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    302\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
     ]
    }
   ],
   "source": [
    "model = AMDGCNN(10)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.00055)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model.train(True)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADGCNN\n",
    "def train_one_epoch():\n",
    "    torch.enable_grad()\n",
    "    l = 0\n",
    "    p = 0\n",
    "    for i in batch[0:1000]:\n",
    "        label = torch.nn.functional.one_hot(torch.tensor(i[0]), num_classes=7).view(1, -1).float()\n",
    "        g = i[1].coalesce().float()\n",
    "        x = i[2].float()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x.to(device), g.to(device))\n",
    "        loss = criterion(out, label.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        p += 1\n",
    "        l += loss.item()\n",
    "        if p % 100 == 0:\n",
    "            print(f\"Loss: {l}\")\n",
    "            l = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 157.89881592988968\n",
      "Loss: 155.990369617939\n",
      "Loss: 162.08416163921356\n",
      "Loss: 157.4449891448021\n",
      "Loss: 180.31131994724274\n",
      "Loss: 160.04609733819962\n",
      "Loss: 158.67898684740067\n",
      "Loss: 166.98347693681717\n",
      "Loss: 159.89664870500565\n",
      "Loss: 168.99259996414185\n",
      "Loss: 153.63431864976883\n",
      "Loss: 152.45419251918793\n",
      "Loss: 175.26148879528046\n",
      "Loss: 153.39883935451508\n",
      "Loss: 168.10096210241318\n",
      "Loss: 154.82251408696175\n",
      "Loss: 157.4013516306877\n",
      "Loss: 164.74410432577133\n",
      "Loss: 162.1094577908516\n",
      "Loss: 165.691240131855\n",
      "Loss: 156.7703014612198\n",
      "Loss: 149.98195579648018\n",
      "Loss: 174.4571948647499\n",
      "Loss: 155.6932834982872\n",
      "Loss: 170.439120054245\n",
      "Loss: 160.54885318875313\n",
      "Loss: 162.85599356889725\n",
      "Loss: 164.68665331602097\n",
      "Loss: 160.38610470294952\n",
      "Loss: 173.49579071998596\n",
      "Loss: 158.36921721696854\n",
      "Loss: 156.43072420358658\n",
      "Loss: 176.78861433267593\n",
      "Loss: 166.65884673595428\n",
      "Loss: 169.12505966424942\n",
      "Loss: 156.14981651306152\n",
      "Loss: 157.65793257951736\n",
      "Loss: 165.05918353796005\n",
      "Loss: 163.56419587135315\n",
      "Loss: 169.02613192796707\n",
      "Loss: 153.31239753961563\n",
      "Loss: 154.1168352663517\n",
      "Loss: 174.3578538298607\n",
      "Loss: 162.98406720161438\n",
      "Loss: 168.9034811258316\n",
      "Loss: 154.32057510316372\n",
      "Loss: 164.68847578763962\n",
      "Loss: 165.26969212293625\n",
      "Loss: 161.09822535514832\n",
      "Loss: 175.13338142633438\n",
      "Loss: 160.45870745182037\n",
      "Loss: 160.8436262011528\n",
      "Loss: 176.56263983249664\n",
      "Loss: 173.24153178930283\n",
      "Loss: 173.3901440501213\n",
      "Loss: 168.58439481258392\n",
      "Loss: 160.37804359197617\n",
      "Loss: 162.47216975688934\n",
      "Loss: 163.21904677152634\n",
      "Loss: 168.02138245105743\n",
      "Loss: 159.32325965166092\n",
      "Loss: 149.69898796081543\n",
      "Loss: 175.0050408244133\n",
      "Loss: 160.62858814001083\n",
      "Loss: 170.59674525260925\n",
      "Loss: 157.92164662480354\n",
      "Loss: 162.02203768491745\n",
      "Loss: 156.79185503721237\n",
      "Loss: 159.18133133649826\n",
      "Loss: 159.01935771107674\n",
      "Loss: 153.7595683336258\n",
      "Loss: 147.16553527116776\n",
      "Loss: 169.7278162240982\n",
      "Loss: 152.5789532661438\n",
      "Loss: 164.05456882715225\n",
      "Loss: 170.5128961801529\n",
      "Loss: 167.2669541835785\n",
      "Loss: 162.5245422720909\n",
      "Loss: 160.11455821990967\n",
      "Loss: 172.33999556303024\n",
      "Loss: 154.70828938484192\n",
      "Loss: 147.16860003769398\n",
      "Loss: 174.50630974769592\n",
      "Loss: 159.32607680559158\n",
      "Loss: 162.67540723085403\n",
      "Loss: 164.10139432549477\n",
      "Loss: 167.82251918315887\n",
      "Loss: 164.41833347082138\n",
      "Loss: 158.51800298690796\n",
      "Loss: 172.81941390037537\n",
      "Loss: 160.114899456501\n",
      "Loss: 158.9051849246025\n",
      "Loss: 169.16909611225128\n",
      "Loss: 163.6982379257679\n",
      "Loss: 161.7444771528244\n",
      "Loss: 159.3904816713184\n",
      "Loss: 161.7045079767704\n",
      "Loss: 164.26866599917412\n",
      "Loss: 160.9975632429123\n",
      "Loss: 157.380331851542\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    train_one_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.no_grad()\n",
    "labels = []\n",
    "preds = []\n",
    "for i in batch[1000:]:\n",
    "        labels.append(i[0])\n",
    "        g = i[1].coalesce().float()\n",
    "        x = i[2].float()\n",
    "        out = model(x.to(device), g.to(device)).softmax(1)\n",
    "        preds.append(out.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7273)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torcheval.metrics import MulticlassAUROC\n",
    "metric = MulticlassAUROC(num_classes=7)\n",
    "metric.update(torch.stack(preds).view(len(batch[1000:]), 7).to(device), torch.tensor(labels).to(device))\n",
    "metric.compute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

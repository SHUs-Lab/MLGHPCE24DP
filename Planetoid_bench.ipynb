{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from scipy.sparse.csgraph import shortest_path\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Conv1d, MaxPool1d, Linear, Dropout,BCEWithLogitsLoss\n",
    "import torch_geometric\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, aggr, GATConv\n",
    "from torch_geometric.utils import k_hop_subgraph, to_scipy_sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = RandomLinkSplit(num_val=0.05, num_test=0.1,\n",
    "is_undirected=True, split_labels=True)\n",
    "dataset = Planetoid('.', name='Cora',\n",
    "transform=transform)\n",
    "train_data, val_data, test_data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seal_processing(dataset, edge_label_index, y):\n",
    "    data_list = []\n",
    "    for src, dst in edge_label_index.t().tolist():\n",
    "        sub_nodes, sub_edge_index, mapping, _ = k_hop_subgraph([src, dst], 2, dataset.edge_index, relabel_nodes=True)\n",
    "        src, dst = mapping.tolist()\n",
    "        mask1 = (sub_edge_index[0] != src) | (sub_edge_index[1] != dst)\n",
    "        mask2 = (sub_edge_index[0] != dst) | (sub_edge_index[1] != src)\n",
    "        sub_edge_index = sub_edge_index[:, mask1 & mask2]\n",
    "        src, dst = (dst, src) if src > dst else (src,dst)\n",
    "        adj = to_scipy_sparse_matrix(sub_edge_index, num_nodes=sub_nodes.size(0)).tocsr()\n",
    "        idx = list(range(src)) + list(range(src + 1, adj.shape[0]))\n",
    "        adj_wo_src = adj[idx, :][:, idx]\n",
    "        idx = list(range(dst)) + list(range(dst + 1, adj.shape[0]))\n",
    "        adj_wo_dst = adj[idx, :][:, idx]\n",
    "        d_src = shortest_path(adj_wo_dst, directed=False,unweighted=True, indices=src)\n",
    "        d_src = np.insert(d_src, dst, 0, axis=0)\n",
    "        d_src = torch.from_numpy(d_src)\n",
    "        d_dst = shortest_path(adj_wo_src, directed=False,unweighted=True, indices=dst-1)\n",
    "        d_dst = np.insert(d_dst, src, 0, axis=0)\n",
    "        d_dst = torch.from_numpy(d_dst)\n",
    "        dist = d_src + d_dst\n",
    "        z = 1 + torch.min(d_src, d_dst) + dist // 2 *(dist // 2 + dist % 2 - 1)\n",
    "        z[src], z[dst], z[torch.isnan(z)] = 1., 1., 0.\n",
    "        z = z.to(torch.long)\n",
    "        node_labels = F.one_hot(z, num_classes=200).to(torch.float)\n",
    "        node_emb = dataset.x[sub_nodes]\n",
    "        node_x = torch.cat([node_emb, node_labels],dim=1)\n",
    "        data = Data(x=node_x, z=z, edge_index=sub_edge_index, y=y)\n",
    "        data_list.append(data)\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_data_list = seal_processing(train_data, train_data.pos_edge_label_index, 1)\n",
    "train_neg_data_list = seal_processing(train_data, train_data.neg_edge_label_index, 0)\n",
    "val_pos_data_list = seal_processing(val_data, val_data.pos_edge_label_index, 1)\n",
    "val_neg_data_list = seal_processing(val_data, val_data.neg_edge_label_index, 0)\n",
    "test_pos_data_list = seal_processing(test_data, test_data.pos_edge_label_index, 1)\n",
    "test_neg_data_list = seal_processing(test_data, test_data.neg_edge_label_index, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_pos_data_list + train_neg_data_list\n",
    "val_dataset = val_pos_data_list + val_neg_data_list\n",
    "test_dataset = test_pos_data_list + test_neg_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32,shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DGCNN(torch.nn.Module):\n",
    "    def __init__(self, dim_in):\n",
    "        super().__init__()\n",
    "        self.gcn1 = GATConv(dim_in, 32)\n",
    "        self.gcn2 = GATConv(32, 32)\n",
    "        self.gcn3 = GATConv(32, 32)\n",
    "        self.gcn4 = GATConv(32, 1)\n",
    "        self.global_pool = aggr.SortAggregation(k=30)\n",
    "        self.conv1 = torch.nn.Conv1d(1, 16, 97, 97)\n",
    "        self.conv2 = torch.nn.Conv1d(16, 32, 5, 1)\n",
    "        self.maxpool = torch.nn.MaxPool1d(2, 2)\n",
    "        self.linear1 = torch.nn.Linear(352, 128)\n",
    "        self.linear2 = torch.nn.Linear(128, 1)\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "    def forward(self, mat, edge_index, batch):\n",
    "        h1 = self.gcn1(mat, edge_index).tanh()\n",
    "        h2 = self.gcn2(h1, edge_index).tanh()\n",
    "        h3 = self.gcn3(h2, edge_index).tanh()\n",
    "        h4 = self.gcn4(h3, edge_index).tanh()\n",
    "        h = torch.cat([h1, h2, h3, h4], dim=-1)\n",
    "        h = self.global_pool(h, batch)\n",
    "        h = h.view(h.size(0), 1, h.size(-1))\n",
    "        h = self.conv1(h).relu()\n",
    "        h = self.maxpool(h)\n",
    "        h = self.conv2(h).relu()\n",
    "        h = h.view(h.size(0), -1)\n",
    "        h = self.linear1(h).relu()\n",
    "        h = self.dropout(h)\n",
    "        h = self.linear2(h).sigmoid()\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AMDGCNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.gcn1 = torch_geometric.nn.GATConv(16, 32, edge_dim=2)\n",
    "        self.gcn2 = torch_geometric.nn.GATConv(32, 32, edge_dim=2)\n",
    "        self.gcn3 = torch_geometric.nn.GATConv(32, 32, edge_dim=2)\n",
    "        self.gcn4 = AltGraphConv()\n",
    "        self.global_pool = torch_geometric.nn.aggr.SortAggregation(k=30)\n",
    "        self.conv1 = torch.nn.Conv1d(1, 16, 97, 97)\n",
    "        self.conv2 = torch.nn.Conv1d(16, 32, 5, 1)\n",
    "        self.maxpool = torch.nn.MaxPool1d(2, 2)\n",
    "        self.linear1 = torch.nn.Linear(352, 128)\n",
    "        self.linear2 = torch.nn.Linear(128, 1)\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "    def forward(self, mat, edge_index):\n",
    "        h1 = self.gcn1(mat, edge_index).tanh()\n",
    "        h2 = self.gcn2(h1, edge_index).tanh()\n",
    "        h3 = self.gcn3(h2, edge_index).tanh()\n",
    "        h4 = self.gcn4(h3, edge_index).tanh()\n",
    "        h = torch.cat([h1, h2, h3, h4], dim=-1)\n",
    "        h = self.global_pool(h)\n",
    "        h = h.view(h.size(0), 1, h.size(-1))\n",
    "        h = self.conv1(h).relu()\n",
    "        h = self.maxpool(h)\n",
    "        h = self.conv2(h).relu()\n",
    "        h = h.view(h.size(0), -1)\n",
    "        h = self.linear1(h).relu()\n",
    "        h = self.dropout(h)\n",
    "        h = self.linear2(h).sigmoid()\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = DGCNN(train_dataset[0].num_features).to(device)     # Use model = AMDGCNN for benchmarking AMDGCNN\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.0001)\n",
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = criterion(out.view(-1), data.y.to(torch.float))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) * data.num_graphs\n",
    "    return total_loss / len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    y_pred, y_true = [], []\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        y_pred.append(out.view(-1).cpu())\n",
    "        y_true.append(data.y.view(-1).cpu().to(torch.float))\n",
    "    auc = roc_auc_score(torch.cat(y_true), torch.cat(y_pred))\n",
    "    ap = average_precision_score(torch.cat(y_true),torch.cat(y_pred))\n",
    "    return auc, ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 | Loss: 0.6131 | ValAUC: 0.8594 | Val AP: 0.8815\n",
      "Epoch  1 | Loss: 0.4576 | ValAUC: 0.8919 | Val AP: 0.9123\n",
      "Epoch  2 | Loss: 0.4140 | ValAUC: 0.9115 | Val AP: 0.9284\n",
      "Epoch  3 | Loss: 0.3802 | ValAUC: 0.9232 | Val AP: 0.9354\n",
      "Epoch  4 | Loss: 0.3537 | ValAUC: 0.9286 | Val AP: 0.9411\n",
      "Epoch  5 | Loss: 0.3333 | ValAUC: 0.9264 | Val AP: 0.9415\n",
      "Epoch  6 | Loss: 0.3213 | ValAUC: 0.9260 | Val AP: 0.9415\n",
      "Epoch  7 | Loss: 0.3105 | ValAUC: 0.9251 | Val AP: 0.9411\n",
      "Epoch  8 | Loss: 0.2989 | ValAUC: 0.9230 | Val AP: 0.9390\n",
      "Epoch  9 | Loss: 0.2895 | ValAUC: 0.9197 | Val AP: 0.9366\n",
      "Epoch 10 | Loss: 0.2787 | ValAUC: 0.9198 | Val AP: 0.9368\n",
      "Epoch 11 | Loss: 0.2705 | ValAUC: 0.9215 | Val AP: 0.9383\n",
      "Epoch 12 | Loss: 0.2646 | ValAUC: 0.9224 | Val AP: 0.9386\n",
      "Epoch 13 | Loss: 0.2576 | ValAUC: 0.9238 | Val AP: 0.9403\n",
      "Epoch 14 | Loss: 0.2481 | ValAUC: 0.9197 | Val AP: 0.9368\n",
      "Epoch 15 | Loss: 0.2437 | ValAUC: 0.9191 | Val AP: 0.9362\n",
      "Epoch 16 | Loss: 0.2415 | ValAUC: 0.9196 | Val AP: 0.9383\n",
      "Epoch 17 | Loss: 0.2334 | ValAUC: 0.9181 | Val AP: 0.9368\n",
      "Epoch 18 | Loss: 0.2314 | ValAUC: 0.9168 | Val AP: 0.9349\n",
      "Epoch 19 | Loss: 0.2244 | ValAUC: 0.9174 | Val AP: 0.9356\n",
      "Epoch 20 | Loss: 0.2229 | ValAUC: 0.9163 | Val AP: 0.9347\n",
      "Epoch 21 | Loss: 0.2176 | ValAUC: 0.9153 | Val AP: 0.9346\n",
      "Epoch 22 | Loss: 0.2112 | ValAUC: 0.9111 | Val AP: 0.9315\n",
      "Epoch 23 | Loss: 0.2091 | ValAUC: 0.9112 | Val AP: 0.9312\n",
      "Epoch 24 | Loss: 0.2073 | ValAUC: 0.9085 | Val AP: 0.9312\n",
      "Epoch 25 | Loss: 0.2011 | ValAUC: 0.9076 | Val AP: 0.9303\n",
      "Epoch 26 | Loss: 0.1965 | ValAUC: 0.9076 | Val AP: 0.9308\n",
      "Epoch 27 | Loss: 0.1956 | ValAUC: 0.9106 | Val AP: 0.9323\n",
      "Epoch 28 | Loss: 0.1891 | ValAUC: 0.9033 | Val AP: 0.9274\n",
      "Epoch 29 | Loss: 0.1863 | ValAUC: 0.9097 | Val AP: 0.9310\n",
      "Epoch 30 | Loss: 0.1857 | ValAUC: 0.9099 | Val AP: 0.9314\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(31):\n",
    "    loss = train()\n",
    "    val_auc, val_ap = test(val_loader)\n",
    "    print(f'Epoch {epoch:>2} | Loss: {loss:.4f} | ValAUC: {val_auc:.4f} | Val AP: {val_ap:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.8887 | Test AP 0.9123\n"
     ]
    }
   ],
   "source": [
    "test_auc, test_ap = test(test_loader)\n",
    "print(f'Test AUC: {test_auc:.4f} | Test AP {test_ap:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
